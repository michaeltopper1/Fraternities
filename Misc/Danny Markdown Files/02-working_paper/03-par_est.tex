% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[
]{article}
\usepackage{lmodern}
\usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\hypersetup{
  pdftitle={par\_est},
  hidelinks,
  pdfcreator={LaTeX via pandoc}}
\urlstyle{same} % disable monospaced font for URLs
\usepackage[margin=1in]{geometry}
\usepackage{graphicx,grffile}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{-\maxdimen} % remove section numbering

\title{par\_est}
\author{}
\date{\vspace{-2.5em}}

\begin{document}
\maketitle

\hypertarget{estimation-of-parameters-and-counterfactual}{%
\section{Estimation of Parameters and
Counterfactual}\label{estimation-of-parameters-and-counterfactual}}

I estimate the parameters using a Bayesian approach.
\(g_{T_0+i}\left(y_{0,1},\dots,y_{0,T_0}\right)\) will be estimated as a
conditional distribution on the observable:

\begin{align}
g_{T_0+i}\left(y_{0,1},\dots,y_{0,T_0}\right) \sim f_{T_0+i}(y_{0,T_0+i}|\mathbf{y},\mathbf{y_0})
\end{align}

This distribution can be rewritten as a model average on parameters:

\begin{align}
f_{T_0+i}(y_{0,T_0+i}|\mathbf{y},\mathbf{y_0}) = \int_{v \in V} f_{T_0+i}(y_{0,T_0+i}|\mathbf{y},\mathbf{y_0},v)Pr(v|\mathbf{y},\mathbf{y_0})dv
\end{align}

Given the state space setup,
\(f_{T_0+i}(y_{0,T_0+i}|\mathbf{y},\mathbf{y_0},v) \sim \mathcal{N}\left(\sum_{j=1}^{J+1} \beta_{j,T_0+i}y_{j,T_0+i},\sigma^2\right)\).
To estimate the posterior parameters, I incorporate a variant of the
Bayesian Lasso {[}@park\_bayesian\_2008{]}. I model the shrinkage using
the global-local shrinkage framework {[}@bernardo\_shrink\_2011{]}. This
framework is designed to apply stronger amounts of shrinkage for smaller
parameter estimates allowing larger parameter estimates to ``escape''
leading to better in-sample and out-of-sample fits.

\hypertarget{reparameterization}{%
\subsection{Reparameterization}\label{reparameterization}}

Equation \eqref{eq:rw} can be rewritten to decompose \(\beta_{j,t}\)
into a time varying and constant components \footnote{See
  {[}@fruhwirth-schnatter\_stochastic\_2010{]} for more details.}:

\[
\begin{aligned}
\beta_{j,t}&=\beta_{j}+\tilde{\beta}_{j,t}\sqrt{\theta_j}\\
\tilde{\beta}_{j,t}&= \tilde{\beta}_{j,t-1}+\tilde{\eta}_{j,t} & \tilde{\eta}_{j,t} \sim N(0,1)\\
\tilde{\beta}_{j,0}& \sim N(0,P_{jj})\\
\end{aligned}
\]

\(\beta_j\) can now be interpreted as the time invariant component of
\(\beta_{j,t}\) and \(\sqrt{\theta_j}\tilde{\beta}_{j,t}\) the time
varying component. \(\sqrt{\theta_j}\) is defined as the root of
\(\theta_j\) and allowed to take both positive and negative values.
Defining \(\sqrt{\theta_j}\) in this manner allows 0 to be an interior
point in the prior distribution. This is a desirable feature when
performing Bayesian shrinkage {[}@bitto\_achieving\_2019{]}. The
absolute value of \(\sqrt{\theta_j}\) is the standard deviation of the
time varying coefficient. Substituting the reformulation back into the
original equation yields the proposed state space model.

\begin{assumption}[Model]
The Time Varying Parameter Bayesian Lasso (TVP-BL) takes the following form:
\end{assumption}

\begin{align}
y_{0,t}(0)&=\sum_{j=1}^{J+1} \left(\beta_{j}+\tilde{\beta}_{j,t}\sqrt{\theta_j}\right)y_{j,t}+\epsilon_t & \epsilon_t \sim N(0, \sigma^2) \label{eq:rmod1}\\
\tilde{\beta}_{j,t}&= \tilde{\beta}_{j,t-1}+\tilde{\eta}_{j,t} & \tilde{\eta}_{j,t} \sim N(0,1) \label{eq:rmod2}\\
\tilde{\beta}_{j,0}& \sim N(0,P_{jj}) \\
\pi(\mathbf{v}) \label{eq:rmod3}
\end{align}

where \(\pi(\mathbf{v})\) represents the prior distribution of the
parameters with the specific distributions defined below. Equations
\eqref{eq:rmod1} - \eqref{eq:rmod3} constitute the model. This setup is
commonly known as the \emph{non-centered parameterization of state space
models}. This formulation allows estimation of the time varying and time
invariant component of the coefficients individually. The effect of each
control unit can be summarized into one of the four categories: (i) time
varying non-zero, (ii) time invariant, (iii) time varying centered at
zero, and (iv) time invariant zero coefficients (irrelevant). Notice if
\(\sqrt{\theta_j}=0\) for all j, the model is a Bayesian version of the
LASSO estimator discussed in @kinn\_synthetic\_2018. Setting
\(\sqrt{\theta_j}=0\) and restricting \(\beta\) such that
\(\beta_j \in [0,1]\) and \(\sum_j \beta_j =1\) yields a parametric
version of @abadie\_economic\_2003 synthetic control model.

There are 2(J+1)+1 parameters to be estimated: the J+1 time invariant
coefficients (i.e.~\(\beta_j\)'s), the J+1 time varying coefficients
(i.e.~\(\sqrt{\theta_j}\)'s) and the variance (\(\sigma^2\)).

\hypertarget{bayesian-shrinkage-priors}{%
\subsubsection{Bayesian Shrinkage
Priors}\label{bayesian-shrinkage-priors}}

I set up the prior distribution for coefficients
\({\beta}=[\beta_1,\beta_2,...,\beta_{J+1}]\) with variances
\(\alpha^2=[\alpha_1^2,\alpha_2^2,...,\alpha_{J+1}^2]\) as a
\emph{global-local} shrinkage prior:

\[
\begin{aligned}
\beta | \alpha^2, \lambda^2 &\sim \mathcal{N}_{J+1} (0_{J+1}, \lambda^2 diag[\alpha_1^2,...\alpha_{J+1}^2])\\
\alpha_j^2  &\sim \pi(\alpha_j^2)\\
\lambda^2 &\sim \pi(\lambda^2)
\end{aligned}
\]

This prior formulation has gained popularity in the Bayesian framework
due to it's attractive shrinkage properties
(@makalic\_high-dimensional\_2016, @bernardo\_shrink\_2011).
\(\lambda^2\) controls the overall complexity of the model while
\(\alpha_j^2\) produces individual shrinkage. This formulation allows
for strong shrinkage on small coefficients while leaving larger
coefficients relatively unshrunk.

\(\alpha_j^2\) is assigned an exponential distribution with rate 1. The
hierarchical formulation of \(\beta\) and \(\alpha^2\) are identical to
a priori independent Laplace priors. Such a prior forms the Bayesian
LASSO proposed by @park\_bayesian\_2008. @park\_bayesian\_2008 showed
this choice of priors leads to posterior performance similar to the
frequentist machine learning approach LASSO
{[}@tibshirani\_regression\_1996{]}.

\(\lambda^2\) is represented as a half-Cauchy distribution with mean 0
and scale parameter 1. The half-Cauchy is used for the global shrinkage
prior because of the flexibility and better behavior near 0 compared to
alternatives {[}@polson\_half-cauchy\_2011{]}. In addition, the
half-Cauchy has significant amounts of mass at the point 0 leading to
better shrinkage properties.

Like the Laplace distribution, the half-Cauchy has a hierarchical
representation where \(\lambda^2|\zeta_{\beta}\) follows an inverse
gamma with shape parameter 1/2 and rate 1/\(\zeta_{\beta}\). The
hierarchical parameter, \(\zeta_\beta\), follows an inverse gamma with
shape parameter 1/2 and rate parameter 1. The prior distribution for
\(\beta=[\beta_1,\beta_2,...,\beta_{J+1}]\) with variances
\(\alpha^2=[\alpha_1^2,\alpha_2^2,...,\alpha_{J+1}^2]\) are:

\begin{align}
\beta | \alpha^2, \lambda^2 &\sim \mathcal{N}_{J+1} (0_{J+1}, \lambda^2 diag[\alpha_1^2,...\alpha_{J+1}^2])\\
\alpha_j^2  &\sim exp\left(1\right)\\
\lambda^2 |\zeta_\beta &\sim InverseGamma\left(\frac{1}{2}, \frac{1}{\zeta_\beta}\right)\\
\zeta_{\beta} & \sim InverseGamma\left(\frac{1}{2},1\right)
\end{align}

Traditionally, variances have been defined by the inverse gamma
distribution. However, the inverse gamma does not allow for effective
shrinkage given it's support. @fruhwirth-schnatter\_stochastic\_2010
provide an in depth argument for the use of the normal distribution as
an alternative. Briefly, the inverse gamma prior performs poorly in
terms of shrinkage due to 0 being an extreme value in the distribution.
This limits the amount of mass which can be placed at 0 in turn limiting
the amount of shrinkage. This becomes a problem when there is beleived
to be many parameters equal to zero. The normal distribution allows for
mass at zero avoiding this problem. Similarly to \(\beta\), assign the
prior of
\(\sqrt{\theta}=\left[\sqrt{\theta_1},\sqrt{\theta_2},...,\sqrt{\theta_{J+1}}\right]\)
with variances \(\xi^2=\left[\xi_1^2,\xi_2^2,...\xi_{J+1}^2 \right]\)
as:

\begin{align}
\sqrt{\theta} | \xi^2, \kappa^2 &\sim \mathcal{N}_{J+1} (0_{J+1}, \kappa^2 diag[\xi_1^2,...\xi_{J+1}^2])\\
\xi_j^2  &\sim exp\left(1\right)\\
\kappa^2 |\zeta_{\sqrt{\theta}} &\sim InverseGamma\left(\frac{1}{2}, \frac{1}{\zeta_{\sqrt{\theta}}}\right)\\
\zeta_{{\sqrt{\theta}}} & \sim InverseGamma\left(\frac{1}{2},1\right)
\end{align}

\(\sigma^2\) is defined as \(\frac{1}{\sigma^2} \sim Gamma(a_1,a_2)\)
with \emph{shape} hyperparameter \(a_1\) and \emph{scale} hyperparameter
\(a_2\). If \(\sqrt{\theta_j}=0\) for all j, the model collapses to a
time invariant estimation with the Bayesian LASSO performing shrinkage.
A derivation of the posterior distributions can be found in the
appendix.

\end{document}
