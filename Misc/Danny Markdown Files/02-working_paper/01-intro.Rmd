---
title: "intro"
output: pdf_document
---

# Introduction

In this paper, I consider the problem of estimating the causal effect of an intervention on an outcome of interest when there is one unit affected by the intervention and the relationship between the unit of interest and all other units may be non-constant. A common approach to this problem is the synthetic control framework. The goal is to construct a counterfactual for the treated unit as a linear combination of untreated units. The synthetic control method has been used in many areas of economics including (but not limited to) the effects of terrorism [@abadie_economic_2003], trade policies [@billmeier_assessing_2013], natural disasters [@cavallo_catastrophic_2013] and social issues [@powell_imperfect_2018]. 

@abadie_synthetic_2010 show that if there exists some linear combination of untreated units such that a perfect pretreatment estimate of the treated unit exists, then the asymptotic bias of the estimated treatment effect approaches zero as the pretreatment period increases. Their approach simplifies the time series estimation problem to a cross sectional one. Each time period in the pretreatment is an "observation" used to estimate missing "observations" in the post treatment. This approach limits the scope of the tool to constant relationships between treatment and control units. In a time series setting, this method excludes nonstationary data such as integrated processes. If such heterogeneous relationships exist and are ignored, the test of no intervention effect is extremely oversized [@carvalho_perils_2016]. @abadie_synthetic_2010 acknowledge this limitation and explicitly warn against the uses of synthetic control when an accurate counterfactual cannot be constructed.

This paper proposes incorporating time varying coefficients into the synthetic control framework to address such situations. An immediate concern with time varying coefficients is the risk of overfitting. Recent advances in macroeconometric forecasting have developed methods to address this concern [@dangl_predictive_2012; @bitto_achieving_2019; @belmonte_hierarchical_2014]. These methods rely on two ideas: non-centered state space modeling and Bayesian shrinkage. Non-centered state space modeling decomposes time varying parameters into a time varying component and a time invariant component. By decomposing each time varying parameter, Bayesian shrinkage techniques "shrink" irrelevant parameters towards zero increasing out of sample performance. These two techniques allow the proposed model to perform as well as a static-coefficient model when the true data generating process involves only static coefficients and superior otherwise.

First, I propose a time varying parameter model based on recent macroeconometric advances to estimate the counterfactual. Second, I compare a popular state space counterfactual model, @brodersen_inferring_2015, to the proposed model in simulation studies. Prior to this paper, testing of this class of model focused on high frequency data including stock prices and inflation rates [@dangl_predictive_2012; @bitto_achieving_2019]. This differs from a synthetic control setting where data tends to be yearly or monthly with few pre and post periods and potentially many controls. Finally, I compare the model's performance to @brodersen_inferring_2015 and @abadie_synthetic_2010 using the German Reunification [@abadie_comparative_2015] and the California Tobacco tax [@abadie_synthetic_2010] case studies.

## Related Work

Developments to synthetic control fall into three main categories:  i) multiple treatments/outcomes [@xu_generalized_2017; @athey_matrix_2020; @lhour_penalized_2019], ii) inference [@li_statistical_2019; @cattaneo_prediction_2019; @chernozhukov_exact_2019], and iii) counterfactual estimation. This paper is focused on counterfactual estimation. For a full review of synthetic controls, the reader is directed to @abadie_using_2019. For an in depth comparison of multiple synthetic control approaches, the reader is directed to @samartsidis_assessing_2019 and @kinn_synthetic_2018.

An increasingly common issue in the case study literature is more untreated units than pre-treatment periods. For example, @abadie_synthetic_2010 considers a situation in which there are 29 untreated units and 17 pretreatment periods. Past researchers have addressed this issue with machine learning techniques (e.g. @doudchenko_balancing_2016, @athey_matrix_2018). @pang_modeling_2010 recommends a model comparison algorithm using Bayes factors while @pang_bayesian_2020 and @brodersen_inferring_2015 incorporate shrinkage priors. These methods place a majority of mass of the prior distribution at zero. These methods force coefficients biased towards zero which allows for the usage of more covariates than observations and better out of sample predictions while avoiding overfitting.

Bayesian methods have been used to estimate the counterfactual in a synthetic control setting. @brodersen_inferring_2015 models the counterfactual using a combination of spike and slab priors and linear Gaussian state space modeling. The spike and slab priors are used to perform automatic variable selection. The authors allow for the coefficients to be constant or dynamic. However, they warn of the dangers of overfitting and implausibly large probability intervals with dynamic coefficients [@brodersen_inferring_2015]. 

This paper aims to solve the issues @brodersen_inferring_2015 faced when incorporating dynamic coefficients. First, the proposed model incorporates the decomposition of time varying coefficients. Second, the model uses a different set of priors to create the Bayesian LASSO. The decomposition paired with the choice of priors solves the issues of overfitting and implausibly large probability intervals. The proposed model allows for shrinkage on the time varying and time invariant portion of the coefficient. Adding the parameter decomposition and Bayesian Lasso allows for the use of time varying parameters without implausibly large probability intervals. 

@pang_bayesian_2020 develop a Bayesian approach based off of the @xu_generalized_2017 linear factors model. Utilizing @bitto_achieving_2019 non-centered parameterization,  the authors explicitly model the latent factors as well as allowing for time varying coefficients. Similar to this paper, they employ a state-space Bayesian framework with shrinkage priors. This paper differs in several key ways. The proposed model begins with the established non-centered parameterization framework and adds causal assumptions while @pang_bayesian_2020 begins with the linear factors models and incorporates time varying components. The different initial points leads to vastly different functional forms. I focus on the case where there is one treated unit and the only predictors are untreated units, while they extend their model to multiple treated units utilizing additional covariates. The final difference between the two papers is scope and purpose. @pang_bayesian_2020 establish a full Bayesian framework to the synthetic control setting while the purpose of this paper is to introduce time varying parameters to the synthetic control framework and investigate their usefulness. It is not entirely clear the increased flexibility of this model will be beneficial in synthetic control settings given the small sample size. In this manner, the papers can be seen as compliments to one another.
