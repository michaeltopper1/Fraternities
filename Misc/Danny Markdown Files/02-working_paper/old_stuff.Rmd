---
title: "stuff_i removed"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# End of Section 2

In general state space form, the model is written as:

\begin{align}
g_{T_0+i}\left(y_{0,1}(0),\dots,y_{0,T_0}(0)\right)&=y_{.,t}(0){\Xi_t}+\epsilon_t &  \epsilon_t \sim \mathcal{N}(0,\sigma^2) &\quad  \text{observation equation}\\
{\Xi_{t+1}}&=\mathbf{T_t} {\Xi_t} +\mathbf{R_t} \eta_t & \eta_t \sim \mathcal{N}(0,Q) &\quad \text{state equation}\\
{\Xi_0} &\sim \mathcal{N}(a_0, P_0)
\end{align}

where $$
\begin{aligned}
\mathbf{T_t}=I,\ \ \ \mathbf{R_t}=I,\\ 
\mathbf{P_0}=diag\left[\theta_1P_{11},\dots,\theta_{J+1}P_{J+1,J+1}\right],\\
\mathbf{Q}=diag\left[\theta_1,\dots,\theta_{J+1}\right],\\
{\Xi_t}=\begin{bmatrix}
\beta_{1,t}\\
\vdots\\
\beta_{J+1,t}
\end{bmatrix},\ \ \ 
{\Xi_0}=\begin{bmatrix}
\beta_{1}\\
\vdots\\
\beta_{J+1}
\end{bmatrix}
\end{aligned}
$$


where $diag(*)$ represents a diagonal matrix with the specified elements on the diagonal.

The evolution of $\beta_{j,t}$ can be changed by changing $\mathbf{T_t}$. For example, setting $\mathbf{T_t}=diag[\rho_1,\dots, \rho_{J+1}]$ creates an AR(1) process. In addition, adding off diagonal terms add interdependence between the evolution of the coefficients. Setting $\beta_{j,t}=\beta_j$ and allowing for a local linear time trend will yield the original estimator in @brodersen_inferring_2015. The reader is referred to @durbin_time_2012 for an advanced treatment of state space modeling. 


# From section 3

Model averaging can be interpreted as a Bayesian version of ensemble methods. In predictive problems, utilizing ensemble methods has proven useful for lower estimation errors [@athey_ensemble_2019; @kellogg_combining_nodate]. 



# Appendix 

## Linear Gaussian State Space Models

This section presents an introduction to concepts in linear Gaussian state space models following @durbin_time_2012. All notation used in this section of the appendix is only meant for this section of the appendix. 

Identifying time varying coefficients can be thought of as a latent variable estimation problem. State space modeling is a time series concept that allows for modeling latent variables explicitly. This means modeling unobserved components like time trends, seasonality, and time varying coefficients. A state space model is composed of an observation equation and state equation. A general form of these equations follows:

$$
\begin{aligned}
y_t&=Z_t\alpha_t+\epsilon_t & \text{observation equation}\\
\alpha_{t+1}&=T_t \alpha_t +R_t \eta_t & \text{state equation}\\
\alpha_0 &\sim \mathcal{N}(a_0, P_0)
\end{aligned}
$$
where $\epsilon_t \sim \mathcal{N}(0,\sigma_t^2)$ and $\eta_t \sim \mathcal{N}(0,Q_t)$ are independent of all unknown factors. $y_t$ is the observed data and $\alpha_t$ is a combination of observed data (e.g. control variables) and unobserved components (e.g. trend and cycle). In the case of a scalar output, $y_t$, with $m$ variables and $r$ time varying components, $Z_t$ would be a 1 x m dimensional matrix, $\alpha_t$ a m x 1 matrix, and $\epsilon_t$ a scalar. $\alpha_{t+1}$ would also be a m x 1 matrix, $T_t$ an m x m matrix, $R_t$ a m x r matrix and $Q_t$ an r x r matrix. Finally, $a_0$ is m x 1 and $P_0$ is m x m. linear Gaussian state space models are structural models. The assumptions necessary for linear Gaussian state space models are:


1) $\epsilon_t \sim \mathcal{N}(0,\sigma^2_t)$ and $\eta_{t} \sim \mathcal{N}(0, Q_t)$. These errors are also assumed to be serially uncorrelated. This is because they are meant to be random disturbances within the model.

2) The errors must be normal.

3) the state equations can be of lag order 1. Any additional lag orders can be rewritten as order 1 using the state space framework.

