---
title: "disc"
output: pdf_document
---

# Discussion

However, the model applies additional restrictions. These restrictions include parametric assumptions on the errors and prior distributions on the parameters. There are no safeguards against mispecified models. In a Bayesian setting, this may become a point of contention. I recommend varying the prior distribution on the parameters $\beta_j$ and $\sqrt{\theta_j}$ form Bayesian Lasso to other shrinkage methods like horseshoe to test for model sensitivity. This method would be in addition to the in-state and in-time placebo tests initially proposed by [@abadie_synthetic_2010].

A key downside to the Bayesian Lasso prior is interpretation. Bayesian Lasso lacks sparsity meaning it does not choose a subset of controls and set all other parameters to zero. In contrast, the slab and spike prior chooses which control unit to include in the model allowing researchers to discusses the inclusion probability. In addition, *BL-TVP* is slow. Every additional control unit adds another state variable. 
