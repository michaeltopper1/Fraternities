---
title: "Empirical Strategy"
output: pdf_document
---

# Empirical Strategy

## Baseline and Preferred Specifications

The goal of this paper is to identify the average causal effect of fraternity moratoriums on alcohol, drug, and sexual assault offenses across universities that experience moratoriums. In a naive analysis, this would amount to taking a difference of means for moratorium days and non-moratorium days across all universities for each offense. However, there are several issues with identifying such difference of means as a causal effect. First, university police departments each vary considerably in the frequency of reporting offenses. This is the result of differing policing tactics, the departments available resources—such as number of officers per-student—and the overall composition of students at the university. For instance, a police department that oversees a university with a reputation for partying may police considerably different than police department that rarely handles college partying. Second, frequencies of offenses vary depending on the day of the week and the time of year. As an example, alcohol offenses most commonly occur on Fridays, Saturdays and Sundays, and fraternity recruitment is typically in the fall semester. A simple difference of means fails to account for each of these systematic differences between universities, days of the week, and semester. 

To circumvent these issues, I estimate the following baseline difference-in-differences specification using OLS:

\begin{equation}\label{main_model}
Y_{u,t} = \beta Moratorium_{u,t}  + \gamma_{u} + \lambda \mathbb{X}_{t} + \epsilon_{u,t}
\end{equation}

where $Y_{u,t}$ is an outcome of alcohol offenses, drug offenses, or sexual assaults per-25000 enrolled students per academic-calendar day at university $u$ in time $t$. $Moratorium_{u,t}$ is an indicator variable equal to one when university $u$ is undergoing a moratorium at time $t$, $\gamma_u$ is a university-specific fixed effect, $\mathbb{X}_t$ is a vector of time-varying controls that are shared across universities, and $\epsilon_{u,t}$ is the error term.  

Including university-specific fixed effects ($\gamma_u$) in the baseline model accounts for systematic differences between a universities police department and the corresponding student demographic they are are policing. As stated above, a police department may have systematic differences in the frequency of reporting due to the corresponding demographic of the university or their own policing practices. For instance, some police departments may enforce policies against underage drinking stricter than others. Hence, including university-specific fixed effects ensures that moratorium days are compared to non-moratorium days while adjusting for these expected differences in universities. Moreover, $\mathbb{X}_{t}$ includes day of the week, semester type (spring/fall), holiday, and academic year controls. Day of the week controls are included since most offenses occur on the weekends, while semester controls are included to adjust for the fact that fraternity recruitment events usually occur in the fall semester. Lastly, holiday controls are included since there may be less student activity on holidays and academic year controls are included due to differences between fraternity rules and guidelines between academic years. Taken together, the corresponding interpretation of the parameter of interest, $\beta$, is the average difference in offense $Y_{u,t}$ on moratorium days relative to non-moratorium days, conditional on the expected differences between universities, days of the week, holidays, semesters, and academic years. 

The preferred specification slightly modifies Equation \ref{main_model}'s controls. In particular, I interact university-specific and academic-year fixed effects to allow more flexibility in controlling for differences within a university's academic year. Hence, the preferred specification (see column (3) in Table \ref{results}) compares only university-specific academic calendar days with a moratorium to university-specific calendar days without a moratorium while accounting for expected differences between the days of the week, holidays, and semesters. A more data-intensive specification using university-by-academic-year-by-semester fixed effect is analyzed in Section BLANK. However, this specification is not preferred due as its estimates are less conservative and a large fraction (PUT HOW MANY) of moratoriums span across multiple academic-year-semesters. All analysis in this paper utilizes the preferred specification unless otherwise noted. 

## Identification Assumptions

In order for $\beta$ to be interpreted as a casual effect of fraternity moratoriums, there are four main assumptions that need to be satisfied. The first assumption is that the timing of a fraternity moratorium must be as-good-as-random. This means that the enactment of a moratorium must not be correlated with unobserved factors in the error term that affect alcohol, drug, or sexual assault offenses. There are several reasons why this is a plausible assumption. First, fraternity moratoriums are the result of three types of triggering events: a fraternity-related death, a behavior violation, or a sexual assault (see Figure \ref{triggerplot}). Fraternity-related deaths and behavior violations are the result of alcohol poisoning from binge drinking and hazing/rule violations respectively. Since fraternities commonly engage in binge drinking and hazing frequently (CITE), it is reasonable to assume that the timing of these extreme instances were coincidental. Similarly, studies have linked a higher prevalence of sexual assaults to fraternity members  (CITE) and therefore a more salient occurrence is likely to have come by-chance rather than the result of unusual behavior. Second, it is common that the start of each moratorium coincides with its corresponding triggering event. Table \ref{reasons} shows a brief description of each triggering event in addition to the date of the triggering event and date of the enacted moratorium. In 14 of the 16 moratoriums in which the date of the triggering event is available, the moratorium is enacted within three days of the triggering event. Hence, there is little reason to expect that students are anticipating a moratorium. Lastly, according to an online repository of fraternity-related deaths from journalist Hank Nuwer^[See https://www.hanknuwer.com/hazing-deaths/.], there were 19 universities that experienced a fraternity-related death but *did not* undergo a moratorium in the sample period. Hence, it is unlikely that fraternity members or students would expect a fraternity moratorium.


The second assumption is that there are no changes in policing or reporting of offenses between moratorium and non-moratorium days. For instance, if university police reduced the number of on-duty officers during moratorium days in anticipation of less crime, the number of offenses reported in the Daily Crime Logs would be mechanically smaller because of changes in officers, not the moratorium itself. Furthermore, students may have more (or less) inclination to report crimes such as sexual assaults if they act in response to the public pressure that moratoriums place on fraternities.  Since the Daily Crime Logs contain no information on number of on-duty officers or a student's affinity to report crimes change, there is no direct way to test this assumption. However, as an indirect test, I analyze whether the time of occurrence to time of incident changes during moratorium days. In particular, I construct the proportion of each offense that is reported with a lag.^[Only 33 of the 38 universities had data for the date occurred of their incidents. Hence, this test only reflects a subset of the sample.] An offense is defined as being reported with a lag if the date the incident occurred is not equal to the date the offense was reported. This test is motivated by the notion that the amount of time from an occurrence to an official report may be due to factors such as police force staffing or the willingness of students to report. Table \ref{} shows the results of this hypothesis. In each column, I change the definition of a lag to reflect a difference of one, three, seven, and fourteen days between the date occurred and date reported.^[Literature such as CITE use a 3-day lag when applying this test.] In each panel and column, the estimations show tight statistical zeros, therefore exhibiting no difference in the proportion of incidents reported with a lag. 

The third assumption stems from the difference-in-differences design of the model: common trends. While it is impossible to know the number of offenses that university's would have experienced in absence of a moratorium, a difference-in-differences model requires that universities were experiencing similar trends prior to a moratorium. To test this assumption, an event study model is estimated using the preferred specification's controls. H

The fourth and final assumption is that moratoriums have no lasting effects. Equation \ref{main_model} implicitly assumes that student behavior changes during moratoriums, but this behavior change does not persist over time. This is demonstrated through the fact that six universities in the sample experience more than one moratorium in the six-year period. If behavior truly changed, there would be no reason to enact multiple moratoriums. Moreover, I test this assumption by enriching the model with an indicator function for the week before and week after a moratorium. As discussed later, there is no evidence that there are persistent effects in the week following a moratorium. On the contrary, there is evidence that the week after exhibits slight increases in offenses.




### No Lasting Effects 

First talk about how the moratorium variable must be exogenous. Reasons why this may be: the fact that there is generally no anticipation - of the 15 events that I have the triggering event date for, most of them are a 1 or 2 day delay. Need to talk about how fraternity activity is relatively constant throught. Hazing violations are always occurring at each school, all of tem have hazing rules and regulations on their website. The triggering events are of three types - one is a death from overdose of alcohol - this is typical behavior - cite the binge drinking fraternity papers. Talk about how this could be the result of one party randomly gone "too far". 

Second talk about how the model assumes that there are no lasting effects of each moratorium. The reasons why this can be believable is because some schools experience multiple moratoriums, thus showing that behavior really is not changing. As a check of this, I include an indicator for the week before and week after. There is a precipitous dip in offenses during, and immediately after this rises back to normal levels. 

Next talk about how the moratorium must not change the type of reporting that police officers are doing. If police systematically change their police effort during a moratorium to being less or more strict, then the effect of the moratorium would be spoiled. Talk about how this is inherently hard to test because we only observe offenses that are reported, not the all offenses occurring. Thus, I need an indirect test to get at this. To analyze this, I use the difference in the date reported and the date occurred to see if there is any change in the "lag" of reports. As a stylized example, sexual assaults may increase if more students decide to come forward once there is already outward pressure on the fraternities. Or on the other hand, student's may delay their reports of sexual assaults even more out of fear of retaliation from fraternities. 

Lastly talk about the common trends assumption. We must assume that schools would have experienced the same amount of offenses had they not gone through the moratorium. To do this, I use an event study. Explain the event study and the corresponding model. Need to talk about how the events turn on and off and how the end points are binned. 


## Threats to Identification



